"""
Main Entry Point - Script maestro para evaluaci√≥n completa
Ejecuta todas las evaluaciones y genera reportes
"""

import argparse
import sys
from datetime import datetime
from pathlib import Path

print("\n" + "=" * 70)
print("üöÄ RAG EVALUATION SUITE - MAIN CONTROLLER")
print("=" * 70 + "\n")


def run_ragas_evaluation():
    """Ejecuta evaluaci√≥n RAGAS completa"""
    print("\nüìä INICIANDO EVALUACI√ìN RAGAS...\n")
    try:
        from ragas_evaluator import main as ragas_main
        ragas_main()
        print("‚úÖ Evaluaci√≥n RAGAS completada")
        return True
    except Exception as e:
        print(f"‚ùå Error en evaluaci√≥n RAGAS: {e}")
        return False


def run_metrics_dashboard():
    """Ejecuta dashboard de m√©tricas"""
    print("\nüìà GENERANDO DASHBOARD DE M√âTRICAS...\n")
    try:
        from metrics_dashboard import display_metrics_dashboard, print_quick_status
        print_quick_status()
        display_metrics_dashboard()
        print("‚úÖ Dashboard completado")
        return True
    except Exception as e:
        print(f"‚ùå Error en dashboard: {e}")
        return False


def run_quick_quality_check():
    """Ejecuta verificaci√≥n r√°pida de calidad"""
    print("\nüîç VERIFICACI√ìN R√ÅPIDA DE CALIDAD...\n")
    try:
        from rag_metrics_integration import (
            measure_rag_performance,
            quick_quality_check,
            print_quality_report,
            save_session_metrics
        )
        from rag_gemini import rag_answer

        test_queries = [
            "¬øPor qu√© es importante dormir bien?",
            "¬øCu√°les son los macronutrientes?",
            "¬øCu√°nta agua debo beber?",
        ]

        total_score = 0
        for i, query in enumerate(test_queries, 1):
            print(f"\n  [{i}/{len(test_queries)}] Evaluando: {query[:50]}...")
            result = rag_answer(query)
            quality = quick_quality_check(query, result["context_text"], result["answer"])
            total_score += quality["overall_quality_score"]

        avg_score = total_score / len(test_queries)
        print(f"\n  üìä Puntuaci√≥n promedio: {avg_score:.4f}")

        # Guardar sesi√≥n
        save_session_metrics("quick_quality_check.json")
        print("‚úÖ Verificaci√≥n r√°pida completada")
        return True

    except Exception as e:
        print(f"‚ùå Error en verificaci√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False


def generate_full_report():
    """Genera reporte completo en HTML"""
    print("\nüìÑ GENERANDO REPORTE COMPLETO...\n")

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_path = f"rag_evaluation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"

    html_content = f"""
    <!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>RAG Evaluation Report</title>
        <style>
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{ 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                padding: 20px;
                color: #333;
            }}
            .container {{
                max-width: 1000px;
                margin: 0 auto;
                background: white;
                border-radius: 12px;
                box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
                padding: 40px;
            }}
            h1 {{
                color: #667eea;
                margin-bottom: 10px;
                text-align: center;
            }}
            .timestamp {{
                text-align: center;
                color: #999;
                margin-bottom: 30px;
                font-size: 14px;
            }}
            .section {{
                margin: 30px 0;
                padding: 20px;
                border-left: 4px solid #667eea;
                background: #f8f9fa;
                border-radius: 8px;
            }}
            .section h2 {{
                color: #667eea;
                margin-bottom: 15px;
                font-size: 18px;
            }}
            .metric-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 15px;
                margin-top: 15px;
            }}
            .metric-card {{
                background: white;
                padding: 15px;
                border-radius: 8px;
                border-left: 4px solid #764ba2;
            }}
            .metric-name {{
                font-weight: 600;
                color: #667eea;
                font-size: 14px;
            }}
            .metric-value {{
                font-size: 24px;
                font-weight: bold;
                color: #764ba2;
                margin-top: 10px;
            }}
            .status-badge {{
                display: inline-block;
                padding: 5px 10px;
                border-radius: 20px;
                font-size: 12px;
                font-weight: 600;
                margin-top: 10px;
            }}
            .status-good {{
                background: #d4edda;
                color: #155724;
            }}
            .status-warning {{
                background: #fff3cd;
                color: #856404;
            }}
            .status-bad {{
                background: #f8d7da;
                color: #721c24;
            }}
            .footer {{
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #eee;
                text-align: center;
                font-size: 12px;
                color: #999;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin-top: 15px;
            }}
            th, td {{
                padding: 10px;
                text-align: left;
                border-bottom: 1px solid #eee;
            }}
            th {{
                background: #667eea;
                color: white;
                font-weight: 600;
            }}
            tr:nth-child(even) {{
                background: #f9f9f9;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üöÄ RAG Evaluation Report</h1>
            <div class="timestamp">Generado: {timestamp}</div>
            
            <div class="section">
                <h2>üìã Resumen Ejecutivo</h2>
                <p>
                    Este reporte contiene los resultados de evaluaci√≥n del sistema RAG usando RAGAS 
                    (Retrieval-Augmented Generation Assessment Framework).
                </p>
            </div>

            <div class="section">
                <h2>üéØ M√©tricas Principales</h2>
                <p>Se han evaluado 4 dimensiones clave del sistema RAG:</p>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li><strong>Faithfulness</strong>: Fidelidad de la respuesta al contexto</li>
                    <li><strong>Answer Relevancy</strong>: Relevancia de la respuesta a la pregunta</li>
                    <li><strong>Context Relevancy</strong>: Relevancia del contexto recuperado</li>
                    <li><strong>Context Precision</strong>: Precisi√≥n del contexto recuperado</li>
                </ul>
            </div>

            <div class="section">
                <h2>üìä Resultados Detallados</h2>
                <p>Para ver resultados completos, consulta:</p>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li><code>ragas_results.json</code> - Resultados en formato JSON</li>
                    <li><code>ragas_results.csv</code> - Resultados en formato CSV</li>
                    <li><code>ragas_evaluations/metrics_history.csv</code> - Hist√≥rico de evaluaciones</li>
                </ul>
            </div>

            <div class="section">
                <h2>üí° Recomendaciones</h2>
                <ul style="margin-left: 20px;">
                    <li>‚úì Ejecuta evaluaciones regularmente (al menos semanal)</li>
                    <li>‚úì Monitorea tendencias en m√©tricas</li>
                    <li>‚úì Usa dashboard para seguimiento visual</li>
                    <li>‚úì Documenta cambios en c√≥digo antes de evaluar</li>
                    <li>‚úì Mejora iterativamente basado en resultados</li>
                </ul>
            </div>

            <div class="section">
                <h2>üìà Pr√≥ximos Pasos</h2>
                <ol style="margin-left: 20px;">
                    <li>Revisar <code>RAGAS_GUIDE.md</code> para documentaci√≥n completa</li>
                    <li>Ejecutar: <code>python metrics_dashboard.py dashboard</code></li>
                    <li>Analizar m√©tricas y identificar √°reas de mejora</li>
                    <li>Implementar mejoras en el c√≥digo</li>
                    <li>Re-evaluar despu√©s de cambios</li>
                </ol>
            </div>

            <div class="footer">
                <p>RAG Evaluation Suite | Powered by RAGAS Framework</p>
                <p>üìö Documentaci√≥n: RAGAS_GUIDE.md</p>
            </div>
        </div>
    </body>
    </html>
    """

    with open(report_path, "w", encoding="utf-8") as f:
        f.write(html_content)

    print(f"‚úÖ Reporte HTML generado: {report_path}")
    return True


def main():
    """Men√∫ principal"""
    parser = argparse.ArgumentParser(
        description="RAG Evaluation Suite - Evaluaci√≥n completa de sistemas RAG"
    )

    parser.add_argument(
        "command",
        nargs="?",
        default="help",
        choices=[
            "full",
            "ragas",
            "dashboard",
            "quick",
            "report",
            "help",
        ],
        help="Comando a ejecutar",
    )

    args = parser.parse_args()

    if args.command == "full":
        print("üîÑ Ejecutando evaluaci√≥n COMPLETA...\n")
        success = True
        success &= run_ragas_evaluation()
        success &= run_metrics_dashboard()
        success &= generate_full_report()

        if success:
            print("\n" + "=" * 70)
            print("‚úÖ EVALUACI√ìN COMPLETA EXITOSA")
            print("=" * 70)
            print("\nüìÅ Archivos generados:")
            print("  - ragas_results.json")
            print("  - ragas_results.csv")
            print("  - ragas_evaluation_report_*.html")
            print("  - ragas_evaluations/metrics_history.csv\n")
        else:
            print("\n" + "=" * 70)
            print("‚ö†Ô∏è EVALUACI√ìN COMPLETADA CON ADVERTENCIAS")
            print("=" * 70 + "\n")

    elif args.command == "ragas":
        print("üîÑ Ejecutando RAGAS...\n")
        run_ragas_evaluation()

    elif args.command == "dashboard":
        print("üîÑ Mostrando DASHBOARD...\n")
        run_metrics_dashboard()

    elif args.command == "quick":
        print("üîÑ Verificaci√≥n R√ÅPIDA...\n")
        run_quick_quality_check()

    elif args.command == "report":
        print("üîÑ Generando REPORTE...\n")
        generate_full_report()

    elif args.command == "help":
        print("""
COMANDOS DISPONIBLES:

  full       - Evaluaci√≥n COMPLETA (RAGAS + Dashboard + Reporte)
  ragas      - Solo RAGAS evaluation
  dashboard  - Solo metrics dashboard
  quick      - Verificaci√≥n r√°pida de calidad
  report     - Generar reporte HTML

EJEMPLOS:
  
  python evaluate_all.py full
  python evaluate_all.py ragas
  python evaluate_all.py dashboard
  python evaluate_all.py quick

DOCUMENTACI√ìN:
  
  Ver RAGAS_GUIDE.md para gu√≠a completa
        """)

    print("\n" + "=" * 70)
    print("‚ú® Evaluaci√≥n completada")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Evaluaci√≥n interrumpida por usuario")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
